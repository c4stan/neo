#version 450

#include "xs.glsl"

#include "common.glsl"

#extension GL_EXT_debug_printf : enable

layout ( binding = 0, set = xs_shader_binding_set_dispatch_m ) uniform draw_uniforms_t {
    vec2 resolution_f32;
    uint hiz_mip_count;
} draw_uniforms;

layout ( binding = 1, set = xs_shader_binding_set_dispatch_m ) uniform texture2D tex_normal;
layout ( binding = 2, set = xs_shader_binding_set_dispatch_m ) uniform texture2D tex_material;
layout ( binding = 3, set = xs_shader_binding_set_dispatch_m ) uniform texture2D tex_color;
layout ( binding = 4, set = xs_shader_binding_set_dispatch_m ) uniform texture2D tex_hiz;

layout ( binding = 5, set = xs_shader_binding_set_dispatch_m ) uniform writeonly image2D img_color;
layout ( binding = 6, set = xs_shader_binding_set_dispatch_m, r16f ) uniform writeonly image2D img_intersect_dist;

layout ( binding = 7, set = xs_shader_binding_set_dispatch_m ) uniform sampler sampler_point;

layout ( local_size_x = 8, local_size_y = 8, local_size_z = 1 ) in;

vec3 ggx_sample ( vec2 e, vec3 wo, vec3 normal, float roughness ) {
    float theta = atan ( roughness * sqrt ( e.x / ( 1.f - e.x ) ) );
    float phi = PI * 2.f * e.y;
    vec3 h = vec3_from_spherical ( theta, phi );

    mat3 tnb = tnb_from_normal ( normal );
    h = normalize ( tnb * h );

    vec3 wi = ( h * dot ( wo, h ) * 2 ) - wo;
    return wi;
}

// Heitz
// http://jcgt.org/published/0007/04/01/paper.pdf
vec3 sampleGGXVNDF(vec3 Ve, float alpha_x, float alpha_y, float U1, float U2)
{
    // Section 3.2: transforming the view direction to the hemisphere configuration
    vec3 Vh = normalize(vec3(alpha_x * Ve.x, alpha_y * Ve.y, Ve.z));
    // Section 4.1: orthonormal basis (with special case if cross product is zero)
    float lensq = Vh.x * Vh.x + Vh.y * Vh.y;
    vec3 T1 = lensq > 0 ? vec3(-Vh.y, Vh.x, 0) / sqrt (lensq) : vec3(1,0,0);
    vec3 T2 = cross(Vh, T1);
    // Section 4.2: parameterization of the projected area
    float r = sqrt(U1);
    float phi = 2.0 * PI * U2;
    float t1 = r * cos(phi);
    float t2 = r * sin(phi);
    float s = 0.5 * (1.0 + Vh.z);
    t2 = (1.0 - s)*sqrt(1.0 - t1*t1) + s*t2;
    // Section 4.3: reprojection onto hemisphere
    vec3 Nh = t1*T1 + t2*T2 + sqrt(max(0.0, 1.0 - t1*t1 - t2*t2))*Vh;
    // Section 3.4: transforming the normal back to the ellipsoid configuration
    vec3 Ne = normalize(vec3(alpha_x * Nh.x, alpha_y * Nh.y, max(0.0, Nh.z)));
    return Ne;
}

vec3 ggx_sample_vndf ( vec2 e, vec3 wo, vec3 normal, float roughness ) {
    mat3 tbn = tbn_from_normal ( normal );
    vec3 view_tangent = normalize ( transpose ( tbn ) * wo );
    vec3 h = sampleGGXVNDF ( view_tangent, roughness, roughness, e.x, e.y );
    h = normalize ( tbn * h );
    vec3 wi = ( h * dot ( wo, h ) * 2 ) - wo;
    return wi;
}

void drawLineBresenham(writeonly image2D targetImage, vec2 p1_uv, vec2 p2_uv, vec4 color) {
    // Get the dimensions of the image in pixels
    ivec2 imageSize = imageSize(targetImage);

    // Convert UV coordinates to integer pixel coordinates
    ivec2 p1_px = ivec2(p1_uv * vec2(imageSize));
    ivec2 p2_px = ivec2(p2_uv * vec2(imageSize));

    int dx = abs(p2_px.x - p1_px.x);
    int dy = abs(p2_px.y - p1_px.y);

    int sx = (p1_px.x < p2_px.x) ? 1 : -1;
    int sy = (p1_px.y < p2_px.y) ? 1 : -1;

    int err = dx - dy;

    ivec2 current_px = p1_px;

    while (true) {
        // Ensure pixelCoord is within image bounds before writing (good practice)
        if (current_px.x >= 0 && current_px.x < imageSize.x &&
            current_px.y >= 0 && current_px.y < imageSize.y) {
            imageStore(targetImage, current_px, color);
        }

        if (current_px.x == p2_px.x && current_px.y == p2_px.y) break;

        int e2 = 2 * err;
        if (e2 > -dy) {
            err -= dy;
            current_px.x += sx;
        }
        if (e2 < dx) {
            err += dx;
            current_px.y += sy;
        }
    }
}

void draw_debug_line2 ( writeonly image2D img, vec2 uv0, vec2 uv1, vec4 color ) {
    ivec2 image_size = imageSize ( img );
    ivec2 p0 = ivec2 ( uv0 * image_size );
    ivec2 p1 = ivec2 ( uv1 * image_size );

    int x0 = p0.x;
    int y0 = p0.y;
    int x1 = p1.x;
    int y1 = p1.y;

    int dx =  abs (x1 - x0), sx = x0 < x1 ? 1 : -1;
    int dy = -abs (y1 - y0), sy = y0 < y1 ? 1 : -1; 
    int err = dx + dy, e2; /* error value e_xy */

    for (;;){  /* loop */
        imageStore(img_color, ivec2(x0, y0), color);
        if (x0 == x1 && y0 == y1) break;
        e2 = 2 * err;
        if (e2 >= dy) { err += dy; x0 += sx; } /* e_xy+e_x > 0 */
        if (e2 <= dx) { err += dx; y0 += sy; } /* e_xy+e_y < 0 */
        }
    }

// ---
// TODO: try: downsample depth & normals -> raytrace in half-resolution -> upsample result back using a bi-filter (read half res depth and normals)
void main ( void ) {
    // Compute screen uv
    vec2 screen_uv = vec2 ( gl_GlobalInvocationID.xy / draw_uniforms.resolution_f32 ) + vec2(0.5) / draw_uniforms.resolution_f32;
    //screen_uv = dejitter_uv ( screen_uv );

    // Sample
    // TODO pass prev frame camera data and account for movement when sampling prev frame textures
    //vec3 view_normal = texture ( sampler2D ( tex_normal, sampler_point ), screen_uv ).xyz * 2 - 1;
    vec4 norm_rough_sample = texture ( sampler2D ( tex_normal, sampler_point ), screen_uv );
    vec3 view_normal = normalize ( norm_rough_sample.xyz * 2 - 1 );
    float roughness = norm_rough_sample.w;
    vec4 mat_sample = texture ( sampler2D ( tex_material, sampler_point ), screen_uv );
    float depth = textureLod ( sampler2D ( tex_hiz, sampler_point ), screen_uv, 0 ).x;
    vec3 color = texture ( sampler2D ( tex_color, sampler_point ), screen_uv ).xyz;
    vec3 view_pos = view_from_depth ( screen_uv, depth );

    // Trace
    //vec3 view_ray_dir = reflect ( normalize ( view_pos ), view_normal );

    rng_wang_state_t rng_state = rng_wang_init ( gl_GlobalInvocationID.xy );
    float ex = rng_wang ( rng_state );
    float ey = rng_wang ( rng_state );
    vec2 e2 = vec2 ( ex, ey );
    vec3 wo = normalize ( -view_pos );
    vec3 wi = ggx_sample_vndf ( e2, wo, view_normal, roughness );
    
    vec3 view_ray_dir = wi;
    vec3 sample_color = vec3 ( 0, 0, 0 );
    float sample_distance = 1;

    //view_ray_dir = vec3 ( 0, 1, 1 );

    /*
        depth thickness:
            render objects to the usual depth prepass and gbuffer passes
            render objects to a new depth buffer using frontface culling and closest depth test
            render objects to the thickness buffer, depth equal with the first depth prepass (same way as a forward pass)
                but in the shader compare depth with sampled frontface culled depth, store difference in the thickness buffer
            sample thickness from the SSR shader to determine proper thickness value
    */

    float hit_distance = 0;

    bool ssr_enabled = mat_sample.x == 1;
    if ( ssr_enabled && depth < 1 ) {
        vec3 hit_screen_pos;
        float hit_depth;
        bool hit;

        //if ( roughness < 0.09 ) {
        //    hit = trace_screen_space_ray ( hit_screen_pos, hit_depth, view_pos, view_ray_dir, tex_hiz, draw_uniforms.hiz_mip_count, sampler_point, 100 );
        //} else {
        //    hit = trace_screen_space_ray_linear ( hit_screen_pos, hit_depth, view_pos, view_ray_dir, tex_hiz, sampler_point, 100, 10 );
        //}
        hit = trace_screen_space_ray ( hit_screen_pos, hit_depth, view_pos, view_ray_dir, tex_hiz, draw_uniforms.hiz_mip_count, sampler_point, 100 );
        //hit = trace_screen_space_ray_linear ( hit_screen_pos, hit_depth, view_pos, view_ray_dir, tex_hiz, sampler_point, 100, 10 );

        if ( hit ) {
            if ( length ( screen_uv - hit_screen_pos.xy ) < 0.01 ) {
                //draw_debug_line ( img_color, screen_uv, hit_screen_pos.xy, vec4 ( 1, 0, 0, 1 ) );
            }
            vec3 hit_color = texture ( sampler2D ( tex_color, sampler_point ), hit_screen_pos.xy ).xyz;
            float depth_delta = - ( linearize_depth ( hit_screen_pos.z ) - linearize_depth ( hit_depth ) );
            float depth_threshold = 0.4;
            //sample_color = mix ( hit_color, vec3 ( 0, 0, 0 ), clamp ( depth_delta, 0, depth_threshold ) * 1.f / depth_threshold );
            hit_color = clamp ( hit_color, vec3(0), vec3(1) );
            sample_color = hit_color;
            vec3 hit_view_pos = view_from_screen ( hit_screen_pos );
            hit_distance = length ( hit_view_pos - view_pos );
        }
    }

    // TODO should the attenuation depend on the specular of the reflecting surface?
    imageStore ( img_color, ivec2 ( gl_GlobalInvocationID.xy ), vec4 ( sample_color, 1 ) );
    imageStore ( img_intersect_dist, ivec2 ( gl_GlobalInvocationID.xy ), vec4 ( hit_distance ) );
}
